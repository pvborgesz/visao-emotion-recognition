{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 226\u001b[0m\n\u001b[1;32m    223\u001b[0m     plot_acc_loss(history)\n\u001b[1;32m    224\u001b[0m     save_model_and_weights(model, test_acc)\n\u001b[0;32m--> 226\u001b[0m run_model()\n",
      "Cell \u001b[0;32mIn [1], line 199\u001b[0m, in \u001b[0;36mrun_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_model\u001b[39m():\n\u001b[1;32m    197\u001b[0m     fer_classes \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mneutral\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhappiness\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msurprise\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msadness\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39manger\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdisgust\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfear\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m--> 199\u001b[0m     X, y \u001b[39m=\u001b[39m preprocess_data()\n\u001b[1;32m    200\u001b[0m     X, y \u001b[39m=\u001b[39m clean_data_and_normalize(X, y)\n\u001b[1;32m    201\u001b[0m     x_train, y_train, x_val, y_val, x_test, y_test \u001b[39m=\u001b[39m split_data(X, y)\n",
      "Cell \u001b[0;32mIn [1], line 30\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m X \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((n_samples, w, h, \u001b[39m1\u001b[39m))\n\u001b[1;32m     29\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_samples):\n\u001b[0;32m---> 30\u001b[0m     X[i] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mfromstring(data[\u001b[39m'\u001b[39;49m\u001b[39mpixels\u001b[39;49m\u001b[39m'\u001b[39;49m][i], dtype\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m, sep\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mreshape((h, w, \u001b[39m1\u001b[39m))\n\u001b[1;32m     32\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mO Kernel falhou ao executar o código na célula atual ou em uma célula anterior. Examine o código nas células para identificar uma possível causa da falha. Clique <a href=\"https://aka.ms/vscodeJupyterKernelCrash\">aqui</a> para obter mais informações. Consulte o <a href='command:jupyter.viewOutput'>log</a> do Jupyter para obter mais detalhes."
     ]
    }
   ],
   "source": [
    "# Two lines that remove tensorflow GPU logs\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    " \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization, Activation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn import model_selection\n",
    "from math import ceil\n",
    "\n",
    "# Loads csv files and appends pixels to X and labels to y\n",
    "def preprocess_data():\n",
    "    data = pd.read_csv('data/fer2013.csv')\n",
    "    labels = pd.read_csv('data/fer2013new.csv') # referente a caracteristica da imagem\n",
    "\n",
    "    orig_class_names = ['neutral', 'happiness', 'surprise', 'sadness', 'anger', 'disgust', 'fear', 'contempt',\n",
    "                        'unknown', 'NF']\n",
    "\n",
    "    n_samples = len(data)\n",
    "    w = 48\n",
    "    h = 48\n",
    "\n",
    "    y = np.array(labels[orig_class_names])\n",
    "    X = np.zeros((n_samples, w, h, 1))\n",
    "    for i in range(n_samples):\n",
    "        X[i] = np.fromstring(data['pixels'][i], dtype=int, sep=' ').reshape((h, w, 1))\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def clean_data_and_normalize(X, y):\n",
    "    orig_class_names = ['neutral', 'happiness', 'surprise', 'sadness', 'anger', 'disgust', 'fear', 'contempt',\n",
    "                        'unknown', 'NF']\n",
    "\n",
    "    # Using mask to remove unknown or NF images\n",
    "    y_mask = y.argmax(axis=-1)\n",
    "    mask = y_mask < orig_class_names.index('unknown')\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "\n",
    "    # Convert to probabilities between 0 and 1\n",
    "    y = y[:, :-2] * 0.1\n",
    "\n",
    "    # Add contempt to neutral and remove it\n",
    "    y[:, 0] += y[:, 7]\n",
    "    y = y[:, :7]\n",
    "\n",
    "    # Normalize image vectors\n",
    "    X = X / 255.0\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def split_data(X, y):\n",
    "    test_size = ceil(len(X) * 0.1)\n",
    "\n",
    "    # Dividindo o dataset em Train e Test\n",
    "    x_train, x_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=test_size)\n",
    "    x_train, x_val, y_train, y_val = model_selection.train_test_split(x_train, y_train, test_size=test_size)\n",
    "\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
    "\n",
    "\n",
    "def data_augmentation(x_train): # Data augmentation para balancear o dataset\n",
    "    shift = 0.1\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        horizontal_flip=True,\n",
    "        height_shift_range=shift,\n",
    "        width_shift_range=shift)\n",
    "    datagen.fit(x_train)\n",
    "    return datagen\n",
    "\n",
    "\n",
    "def show_augmented_images(datagen, x_train, y_train):\n",
    "    it = datagen.flow(x_train, y_train, batch_size=1)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(it.next()[0][0], cmap='gray')\n",
    "        # plt.xlabel(class_names[y_train[i]])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def define_model(input_shape=(48, 48, 1), classes=7):\n",
    "    num_features = 64\n",
    "\n",
    "    model = Sequential() # Camada de entrada\n",
    "\n",
    "    #i wanna build a model with yolo architecture\n",
    "    model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv2D(2 * num_features, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(Conv2D(2 * num_features, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv2D(2 * 2 * num_features, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(Conv2D(2 * 2 * num_features, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(2 * 2 * 2 * num_features, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(2 * 2 * num_features, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(2 * num_features, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "    model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "    # return model\n",
    "\n",
    "    # # i wanna build a model with SSD architecture\n",
    "    # # 1st block\n",
    "    # model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    # model.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu'))\n",
    "    # model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    # model.add(Dropout(0.5))\n",
    "\n",
    "    # # 2nd block\n",
    "    # model.add(Conv2D(2 * num_features, kernel_size=(3, 3), activation='relu'))\n",
    "    # model.add(Conv2D(2 * num_features, kernel_size=(3, 3), activation='relu'))\n",
    "    # model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    # model.add(Dropout(0.5))\n",
    "    \n",
    "    # # 3rd block\n",
    "    # model.add(Conv2D(2 * 2 * num_features, kernel_size=(3, 3), activation='relu'))\n",
    "    # model.add(Conv2D(2 * 2 * num_features, kernel_size=(3, 3), activation='relu'))\n",
    "    # model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    # model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "    # # 1st stage \n",
    "    # model.add(Conv2D(num_features, kernel_size=(3, 3), input_shape=input_shape))\n",
    "    # model.add(BatchNormalization())\n",
    "    # model.add(Activation(activation='relu'))\n",
    "    # model.add(Conv2D(num_features, kernel_size=(3, 3)))\n",
    "    # model.add(BatchNormalization())\n",
    "    # model.add(Activation(activation='relu'))\n",
    "    # model.add(Dropout(0.5)) #Dropout is a simple and powerful regularization technique for neural networks and deep learning models.\n",
    "\n",
    "    # # 2nd stage\n",
    "    # model.add(Conv2D(num_features, (3, 3), activation='relu'))\n",
    "    # model.add(Conv2D(num_features, (3, 3), activation='relu'))\n",
    "    # model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # # 3rd stage\n",
    "    # model.add(Conv2D(2 * num_features, kernel_size=(3, 3)))\n",
    "    # model.add(BatchNormalization())\n",
    "    # model.add(Activation(activation='relu'))\n",
    "    # model.add(Conv2D(2 * num_features, kernel_size=(3, 3)))\n",
    "    # model.add(BatchNormalization())\n",
    "    # model.add(Activation(activation='relu'))\n",
    "\n",
    "    # # 4th stage\n",
    "    # model.add(Conv2D(2 * num_features, (3, 3), activation='relu'))\n",
    "    # model.add(Conv2D(2 * num_features, (3, 3), activation='relu'))\n",
    "    # model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # # 5th stage\n",
    "    # model.add(Conv2D(4 * num_features, kernel_size=(3, 3)))\n",
    "    # model.add(BatchNormalization())\n",
    "    # model.add(Activation(activation='relu'))\n",
    "    # model.add(Conv2D(4 * num_features, kernel_size=(3, 3)))\n",
    "    # model.add(BatchNormalization())\n",
    "    # model.add(Activation(activation='relu'))\n",
    "\n",
    "    # model.add(Flatten()) # achatando o modelo\n",
    "\n",
    "    # # Fully connected neural networks\n",
    "    # model.add(Dense(1024, activation='relu'))\n",
    "    # model.add(Dropout(0.2))\n",
    "    # model.add(Dense(1024, activation='relu'))\n",
    "    # model.add(Dropout(0.2))\n",
    "\n",
    "    # model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def run_model():\n",
    "    fer_classes = ['neutral', 'happiness', 'surprise', 'sadness', 'anger', 'disgust', 'fear']\n",
    "\n",
    "    X, y = preprocess_data()\n",
    "    X, y = clean_data_and_normalize(X, y)\n",
    "    x_train, y_train, x_val, y_val, x_test, y_test = split_data(X, y)\n",
    "    datagen = data_augmentation(x_train)\n",
    "\n",
    "    epochs = 200\n",
    "    batch_size = 64\n",
    "\n",
    "    print(\"X_train shape: \" + str(x_train.shape))\n",
    "    print(\"Y_train shape: \" + str(y_train.shape))\n",
    "    print(\"X_test shape: \" + str(x_test.shape))\n",
    "    print(\"Y_test shape: \" + str(y_test.shape))\n",
    "    print(\"X_val shape: \" + str(x_val.shape))\n",
    "    print(\"Y_val shape: \" + str(y_val.shape))\n",
    "\n",
    "    # Training model from scratch\n",
    "    model = define_model(input_shape=x_train[0].shape, classes=len(fer_classes))\n",
    "    model.summary()\n",
    "    model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "                        steps_per_epoch=len(x_train) // batch_size,\n",
    "                        validation_data=(x_val, y_val), verbose=2)\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "\n",
    "    plot_acc_loss(history)\n",
    "    save_model_and_weights(model, test_acc)\n",
    "\n",
    "run_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mvisualkeras\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m visualkeras\u001b[39m.\u001b[39mlayered_view(model, legend\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import visualkeras\n",
    "visualkeras.layered_view(model, legend=True).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Oct 11 2022, 21:39:54) \n[Clang 14.0.0 (clang-1400.0.29.102)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
